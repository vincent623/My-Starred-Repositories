#!/usr/bin/env python3
"""
My Starred Repositories ä¸»ç¨‹åº V3 - ä¼˜åŒ–ç‰ˆæœ¬
æ”¹è¿›æ ‡ç­¾é€»è¾‘å’Œæ•°æ®æµï¼Œç›´æ¥å†™å…¥æ•°æ®åº“
"""

import os
import json
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any, Optional, Tuple
import requests
from openai import OpenAI
from tqdm import tqdm
import click
from dotenv import load_dotenv
from loguru import logger
import dateutil.parser
import re

# å¯¼å…¥é…ç½®å’Œæ•°æ®åº“
from config import *
from database_v3 import get_database_v3

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logger.remove()
logger.add(lambda msg: tqdm.write(msg, end=""), level="INFO")
logger.add("starred_repos.log", rotation="1 week")

class StarredReposManagerV3:
    """GitHub Star ä»“åº“ç®¡ç†å™¨ V3 - ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        self.github_token = os.getenv("GH_TOKEN")
        self.llm_api_key = os.getenv("LLM_API_KEY")
        self.llm_api_base = os.getenv("LLM_API_BASE_URL", LLM_API_BASE_URL)
        self.llm_model = os.getenv("LLM_MODEL_NAME", LLM_MODEL_NAME)

        # ä¼˜å…ˆä½¿ç”¨ Silicon Flowï¼ˆå¦‚æœæä¾›äº† SILICONFLOW_API_KEY ä¸”æœªæ˜¾å¼è®¾ç½® LLM_API_KEYï¼‰
        if not self.llm_api_key and os.getenv("SILICONFLOW_API_KEY"):
            self.llm_api_key = os.getenv("SILICONFLOW_API_KEY")
            # é»˜è®¤ Silicon Flow ç«¯ç‚¹ä¸æ¨¡å‹
            if not os.getenv("LLM_API_BASE_URL"):
                self.llm_api_base = "https://api.siliconflow.cn/v1"
            if not os.getenv("LLM_MODEL_NAME"):
                self.llm_model = "Qwen/Qwen2.5-Coder-32B-Instruct"
        
        # éªŒè¯å¿…è¦çš„é…ç½®
        if not self.github_token:
            raise ValueError("è¯·è®¾ç½® GH_TOKEN ç¯å¢ƒå˜é‡")
        if not self.llm_api_key:
            raise ValueError("è¯·è®¾ç½® LLM_API_KEY ç¯å¢ƒå˜é‡")
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': f'token {self.github_token}',
            # éœ€è¦ starred_at å­—æ®µå¿…é¡»ä½¿ç”¨ star+json åª’ä½“ç±»å‹
            'Accept': 'application/vnd.github.v3.star+json',
            'User-Agent': 'My-Starred-Repos'
        })
        
        # SSL æ ¡éªŒï¼šé»˜è®¤å¼€å¯ï¼›å¦‚éœ€åœ¨å—é™ç½‘ç»œä¸‹è·³è¿‡æ ¡éªŒï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶
        import urllib3
        disable_verify = os.getenv("DISABLE_SSL_VERIFY", "0") == "1"
        if disable_verify:
            self.session.verify = False
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´å’Œé‡è¯•æœºåˆ¶
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        
        # åˆ›å»ºé€‚é…å™¨å¹¶æŒ‚è½½é‡è¯•ç­–ç•¥
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("https://", adapter)
        self.session.mount("http://", adapter)
        
        # è®¾ç½®è¶…æ—¶æ—¶é—´
        self.session.timeout = 30
        
        self.llm_client = OpenAI(
            api_key=self.llm_api_key,
            base_url=self.llm_api_base,
            default_headers={
                "HTTP-Referer": OPENROUTER_REFERER,
                "X-Title": OPENROUTER_TITLE
            }
        )
        
        # åˆå§‹åŒ–æ•°æ®åº“ V3
        self.db = get_database_v3()
        
        # åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸
        self._initialize_personal_tag_dictionary()
        
        logger.info("StarredReposManagerV3 åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_personal_tag_dictionary(self):
        """åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸"""
        logger.info("åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸...")
        
        # ä»é…ç½®ä¸­åŠ è½½æ ‡ç­¾è¯å…¸
        dictionary = self.db.get_personal_tag_dictionary()
        
        # å¦‚æœè¯å…¸ä¸ºç©ºï¼Œåˆ™ä» TAG_MERGE_RULES åˆå§‹åŒ–
        if not dictionary:
            logger.info("ä¸ªäººæ ‡ç­¾è¯å…¸ä¸ºç©ºï¼Œä»é…ç½®åˆå§‹åŒ–...")
            
            # ä½¿ç”¨æœ‰åºä¸»ç±»åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸
            for main_tag in ORDERED_CATEGORIES:
                self.db.add_personal_tag_to_dictionary(tag=main_tag, description=f"ä¸ªäººæ ‡ç­¾ï¼š{main_tag}", category="ä¸»ç±»")
            
            logger.info(f"å·²åˆå§‹åŒ– {len(TAG_MERGE_RULES)} ä¸ªä¸ªäººæ ‡ç­¾")
        
        # æ˜¾ç¤ºå½“å‰è¯å…¸
        current_dict = self.db.get_personal_tag_dictionary()
        logger.info(f"å½“å‰ä¸ªäººæ ‡ç­¾è¯å…¸åŒ…å« {len(current_dict)} ä¸ªæ ‡ç­¾")
    
    def get_starred_repositories(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ Star çš„ä»“åº“å¹¶ç›´æ¥å†™å…¥æ•°æ®åº“"""
        logger.info("å¼€å§‹è·å– Star ä»“åº“åˆ—è¡¨å¹¶ç›´æ¥å†™å…¥æ•°æ®åº“...")
        
        page = 1
        per_page = 100
        total_processed = 0
        
        try:
            # é¦–å…ˆéªŒè¯è¿æ¥
            logger.info("éªŒè¯ GitHub è¿æ¥...")
            user_response = self.session.get('https://api.github.com/user')
            if user_response.status_code != 200:
                logger.error(f"æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯ï¼ŒçŠ¶æ€ç : {user_response.status_code}")
                logger.error(f"å“åº”å†…å®¹: {user_response.text}")
                return []
            
            user_data = user_response.json()
            logger.info(f"æˆåŠŸè¿æ¥åˆ° GitHubï¼Œç”¨æˆ·: {user_data['login']}")
            
            # è·å–æ‰€æœ‰ star çš„ä»“åº“
            logger.info("å¼€å§‹è·å– Star ä»“åº“...")
            
            while True:
                url = f'https://api.github.com/user/starred?page={page}&per_page={per_page}'
                response = self.session.get(url, timeout=30)
                
                if response.status_code != 200:
                    logger.error(f"è·å– Star ä»“åº“å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    logger.error(f"å“åº”å†…å®¹: {response.text}")
                    break
                
                repos = response.json()
                if not repos:  # æ²¡æœ‰æ›´å¤šæ•°æ®äº†
                    break
                
                for repo in repos:
                    try:
                        # å…¼å®¹ Accept: application/vnd.github.v3.star+json çš„ç»“æ„ï¼ˆå¸¦ repo åµŒå¥—ï¼‰
                        repo_obj = repo.get('repo', repo)
                        repo_info = {
                            'id': str(repo_obj['id']),
                            'name': repo_obj['full_name'],
                            'description': repo_obj.get('description', '') or '',
                            'language': repo_obj.get('language', 'Unknown') or 'Unknown',
                            'topics': repo_obj.get('topics', []) or [],
                            'starred_at': repo.get('starred_at', repo_obj.get('starred_at', '')),
                            'html_url': repo_obj['html_url'],
                            'updated_at': repo_obj.get('updated_at', '')
                        }
                        
                        # è¿‡æ»¤æ’é™¤çš„è¯­è¨€
                        if repo_info['language'] in EXCLUDE_LANGUAGES:
                            continue
                        
                        # ç›´æ¥å†™å…¥æ•°æ®åº“
                        if self.db.insert_repository_direct(repo_info):
                            total_processed += 1
                            
                            # æ›´æ–° GitHub topics ç»Ÿè®¡
                            if repo_info['topics']:
                                self.db.update_github_topics_stats(repo_info['topics'])
                        
                        if total_processed >= MAX_REPOS_TO_PROCESS:
                            logger.info(f"å·²è¾¾åˆ°æœ€å¤§å¤„ç†æ•°é‡ {MAX_REPOS_TO_PROCESS}")
                            return []
                            
                    except Exception as repo_error:
                        logger.warning(f"å¤„ç†ä»“åº“æ—¶å‡ºé”™: {repo_error}")
                        continue
                
                # æ¯å¤„ç†å®Œä¸€é¡µè¾“å‡ºä¸€æ¬¡è¿›åº¦
                logger.info(f"å·²å¤„ç†ç¬¬ {page} é¡µï¼Œå…± {total_processed} ä¸ªä»“åº“...")
                page += 1
                
                # æ£€æŸ¥ API é™åˆ¶
                remaining = int(response.headers.get('X-RateLimit-Remaining', 0))
                if remaining <= 1:
                    reset_time = int(response.headers.get('X-RateLimit-Reset', 0))
                    wait_time = max(reset_time - int(datetime.now().timestamp()), 0)
                    logger.warning(f"API é™åˆ¶å·²è¾¾åˆ°ï¼Œç­‰å¾… {wait_time} ç§’åç»§ç»­...")
                    import time
                    time.sleep(wait_time + 1)
            
            logger.info(f"æˆåŠŸè·å–å¹¶å†™å…¥ {total_processed} ä¸ª Star ä»“åº“")
            return []
            
        except Exception as e:
            logger.error(f"è·å– Star ä»“åº“å¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            return []
    
    def get_enhanced_analysis_prompt(self, repo_info: Dict) -> str:
        """è·å–å¢å¼ºçš„åˆ†ææç¤ºè¯"""
        # è·å–ä¸ªäººæ ‡ç­¾è¯å…¸
        personal_tags = self.db.get_personal_tag_dictionary()
        # å›ºå®šä¸ºé…ç½®çš„ 10 å¤§ä¸»ç±»ï¼›è‹¥åº“ä¸­ä¸å­˜åœ¨åˆ™å…œåº•ä»é…ç½®è¯»å–
        tag_options = [item['tag'] for item in personal_tags] or ORDERED_CATEGORIES
        
        # è·å– GitHub topicsï¼Œå…¼å®¹ä¸åŒçš„å­—æ®µå
        github_topics = repo_info.get('github_topics', repo_info.get('topics', []))
        if isinstance(github_topics, str):
            github_topics = json.loads(github_topics)
        
        prompt = f"""
ä½ æ˜¯èµ„æ·± AI äº§å“/ç ”å‘é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”¨ä¸­æ–‡ç»™å‡ºé«˜è´¨é‡åˆ†æï¼š

ä»“åº“åï¼š{repo_info['name']}
ä»“åº“æè¿°ï¼š{repo_info['description']}
ä¸»è¦è¯­è¨€ï¼š{repo_info['language']}
GitHub ä¸»é¢˜æ ‡ç­¾ï¼š{', '.join(github_topics)}

ä»ä¸‹åˆ—ä¸»ç±»ä¸­é€‰æ‹© 1-3 ä¸ªè¿›è¡Œå½’ç±»ï¼ˆåªèƒ½é€‰è¿™äº›ï¼Œä¸è¦é€ æ–°è¯ï¼‰ï¼š
{', '.join(tag_options)}

è¯·è¾“å‡ºï¼š
1) æ‘˜è¦ï¼ˆ30-80å­—ï¼‰ï¼šè¯´æ˜åšä»€ä¹ˆã€å¦‚ä½•åšã€æ ¸å¿ƒäº®ç‚¹ã€‚
2) æ ‡ç­¾ï¼ˆ1-3ä¸ªï¼‰ï¼šä¸¥æ ¼ä»ç»™å®šä¸»ç±»ä¸­é€‰æ‹©ã€‚
3) ä»·å€¼ï¼ˆ80-160å­—ï¼‰ï¼š
   - å…¸å‹åº”ç”¨åœºæ™¯ï¼ˆè°åœ¨ä½•ç§åœºæ™¯ä½¿ç”¨ï¼‰
   - å…³é”®èƒ½åŠ›/æŠ€æœ¯è·¯çº¿ï¼ˆä¾‹å¦‚ RAG/Agent/Serving/è¯„æµ‹ç­‰ï¼‰
   - é€‚åˆäººç¾¤æˆ–ä¸åŒç±»å·®å¼‚ç‚¹

æ ¼å¼ä¸¥æ ¼å¦‚ä¸‹ï¼ˆä¸è¦æ·»åŠ å¤šä½™è¯´æ˜ï¼‰ï¼š
æ‘˜è¦ï¼š[...]
æ ‡ç­¾ï¼š[æ ‡ç­¾1,æ ‡ç­¾2,æ ‡ç­¾3]
ä»·å€¼ï¼š[...]
"""
        return prompt
    
    def analyze_repository(self, repo_info: Dict) -> Dict:
        """ä½¿ç”¨ LLM åˆ†æå•ä¸ªä»“åº“ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        import time
        
        # è·å–å¢å¼ºçš„åˆ†ææç¤ºè¯
        prompt = self.get_enhanced_analysis_prompt(repo_info)
        
        # è·å–ä¸ªäººæ ‡ç­¾è¯å…¸ç”¨äºéªŒè¯
        personal_tags = self.db.get_personal_tag_dictionary()
        valid_tags = [item['tag'] for item in personal_tags]
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(LLM_MAX_RETRIES):
            try:
                # è°ƒç”¨ LLM
                response = self.llm_client.chat.completions.create(
                    model=self.llm_model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=LLM_TEMPERATURE,
                    max_tokens=500
                )
                
                analysis_text = response.choices[0].message.content
                
                # æ›´å¼ºå¤§çš„è§£æé€»è¾‘
                result = {
                    'summary': '',
                    'tags': [],
                    'value': '',
                    'analyzed_at': datetime.now().isoformat()
                }
                
                # å¤šç§è§£ææ¨¡å¼
                lines = analysis_text.split('\n')
                
                # æ¨¡å¼1ï¼šæ ‡å‡†æ ¼å¼è§£æ
                for line in lines:
                    line = line.strip()
                    if line.startswith('æ‘˜è¦ï¼š'):
                        result['summary'] = line[3:].strip()
                    elif line.startswith('æ ‡ç­¾ï¼š'):
                        tags_text = line[3:].strip()
                        # æ¸…ç†å’ŒéªŒè¯æ ‡ç­¾
                        parsed_tags = []
                        for tag in tags_text.split(','):
                            tag = tag.strip()
                            if tag and tag in valid_tags:
                                parsed_tags.append(tag)
                        result['tags'] = parsed_tags if parsed_tags else ['others']
                    elif line.startswith('ä»·å€¼ï¼š'):
                        result['value'] = line[3:].strip()
                
                # æ¨¡å¼2ï¼šå¦‚æœæ ‡å‡†è§£æå¤±è´¥ï¼Œå°è¯•çµæ´»è§£æ
                if not result['summary'] or not result['tags']:
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
                    import re
                    
                    # æå–æ‘˜è¦
                    summary_match = re.search(r'æ‘˜è¦[ï¼š:]\s*(.*?)(?=æ ‡ç­¾[ï¼š:]|$)', analysis_text)
                    if summary_match:
                        result['summary'] = summary_match.group(1).strip()
                    
                    # æå–æ ‡ç­¾
                    tags_match = re.search(r'æ ‡ç­¾[ï¼š:]\s*(.*?)(?=ä»·å€¼[ï¼š:]|$)', analysis_text)
                    if tags_match:
                        tags_text = tags_match.group(1).strip()
                        parsed_tags = []
                        for tag in tags_text.split(','):
                            tag = tag.strip()
                            if tag and tag in valid_tags:
                                parsed_tags.append(tag)
                        result['tags'] = parsed_tags if parsed_tags else ['others']
                    
                    # æå–ä»·å€¼
                    value_match = re.search(r'ä»·å€¼[ï¼š:]\s*(.*?)(?=$)', analysis_text)
                    if value_match:
                        result['value'] = value_match.group(1).strip()
                
                # æ¨¡å¼3ï¼šå¦‚æœä»ç„¶å¤±è´¥ï¼Œç”Ÿæˆé»˜è®¤ç»“æœ
                if not result['summary']:
                    result['summary'] = repo_info['description'][:50] if repo_info['description'] else 'æš‚æ— æè¿°'
                
                if not result['tags']:
                    result['tags'] = ['others']
                
                if not result['value']:
                    result['value'] = f'ä¸€ä¸ª{repo_info["language"]}é¡¹ç›®'
                
                # éªŒè¯ç»“æœåŸºæœ¬å®Œæ•´æ€§
                if result['summary'] and result['tags']:
                    return result
                else:
                    raise ValueError("è§£æç»“æœä»ç„¶ä¸å®Œæ•´")
                
            except Exception as e:
                logger.warning(f"åˆ†æä»“åº“ {repo_info['name']} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < LLM_MAX_RETRIES - 1:
                    logger.info(f"ç­‰å¾… {LLM_RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(LLM_RETRY_DELAY)
                else:
                    logger.error(f"åˆ†æä»“åº“ {repo_info['name']} æœ€ç»ˆå¤±è´¥: {e}")
                    return {
                        'summary': repo_info['description'][:50] if repo_info['description'] else 'åˆ†æå¤±è´¥',
                        'tags': ['others'],
                        'value': 'æ— æ³•åˆ†ææ­¤ä»“åº“',
                        'analyzed_at': datetime.now().isoformat()
                    }
    
    def process_repositories(self, force_reanalyze: bool = False, limit: Optional[int] = None) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰ä»“åº“ï¼Œç›´æ¥ä½¿ç”¨æ•°æ®åº“"""
        logger.info("å¼€å§‹å¤„ç†ä»“åº“...")
        
        # è·å–éœ€è¦åˆ†æçš„ä»“åº“ï¼›è‹¥å¼ºåˆ¶åˆ™å–å…¨éƒ¨ï¼Œä¸”å¯é™é‡
        if force_reanalyze:
            repos_needing_analysis = self.db.get_repositories_needing_analysis(days_threshold=36500)
        else:
            repos_needing_analysis = self.db.get_repositories_needing_analysis()
        if limit is not None:
            repos_needing_analysis = repos_needing_analysis[:max(0, int(limit))]
        
        if not repos_needing_analysis:
            logger.info("æ²¡æœ‰éœ€è¦åˆ†æçš„ä»“åº“")
            return []
        
        logger.info(f"æ‰¾åˆ° {len(repos_needing_analysis)} ä¸ªéœ€è¦åˆ†æçš„ä»“åº“")
        
        processed_count = 0
        new_repos_this_week = []
        one_week_ago = datetime.now(timezone.utc) - timedelta(days=7)
        
        for i, repo in enumerate(tqdm(repos_needing_analysis, desc="åˆ†æä»“åº“")):
            # åˆ†æä»“åº“
            analysis = self.analyze_repository(repo)
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„åˆ†æç»“æœ
            if self.db.update_repository_analysis(repo['id'], analysis):
                processed_count += 1
                
                # æ›´æ–°ä¸ªäººæ ‡ç­¾ç»Ÿè®¡
                for tag in analysis['tags']:
                    self.db.update_personal_tag_stats(tag)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬å‘¨æ–°å¢
                if repo['starred_at']:
                    starred_time = dateutil.parser.parse(repo['starred_at'])
                    # ç»Ÿä¸€ä¸ºå¸¦æ—¶åŒºçš„ UTC æ—¶é—´
                    if starred_time.tzinfo is None:
                        starred_time = starred_time.replace(tzinfo=timezone.utc)
                    starred_time_utc = starred_time.astimezone(timezone.utc)
                    if starred_time_utc > one_week_ago:
                        new_repos_this_week.append({**repo, **analysis})
            
            # å¢é‡ä¿å­˜ï¼šæ¯å¤„ç† SAVE_INTERVAL ä¸ªä»“åº“æ›´æ–°ä¸€æ¬¡ç»Ÿè®¡
            if (i + 1) % SAVE_INTERVAL == 0:
                logger.info(f"å·²åˆ†æ {i + 1} ä¸ªä»“åº“ï¼Œæ›´æ–°ä¸­é—´æ•°æ®...")
                self.db.rebuild_personal_tag_stats()
        
        logger.info(f"å¤„ç†å®Œæˆï¼Œå…±åˆ†æ {processed_count} ä¸ªä»“åº“")
        return new_repos_this_week
    
    def clean_tag(self, tag: str) -> str:
        """æ¸…ç†æ ‡ç­¾ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
        cleaned = tag.strip()
        
        # åº”ç”¨æ¸…ç†è§„åˆ™
        for pattern, replacement in TAG_CLEAN_RULES.items():
            cleaned = re.sub(pattern, replacement, cleaned)
        
        return cleaned.strip()
    
    def merge_tags(self, tags: List[str]) -> List[str]:
        """åˆå¹¶ç›¸ä¼¼çš„æ ‡ç­¾ï¼ŒåŒ…å«æ¸…ç†åŠŸèƒ½"""
        merged_tags = []
        
        for tag in tags:
            # é¦–å…ˆæ¸…ç†æ ‡ç­¾
            cleaned_tag = self.clean_tag(tag)
            
            if not cleaned_tag:  # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡
                continue
            
            merged = False
            for main_tag, similar_tags in TAG_MERGE_RULES.items():
                if cleaned_tag in similar_tags:
                    if main_tag not in merged_tags:
                        merged_tags.append(main_tag)
                    merged = True
                    break
            
            if not merged:
                merged_tags.append(cleaned_tag)
        
        return merged_tags
    
    def update_tags_data(self) -> None:
        """æ›´æ–°æ ‡ç­¾æ•°æ®ï¼ˆç°åœ¨ä¸»è¦å¤„ç†ä¸ªäººæ ‡ç­¾ï¼‰"""
        logger.info("æ›´æ–°ä¸ªäººæ ‡ç­¾æ•°æ®...")
        
        # é‡æ–°æ„å»ºä¸ªäººæ ‡ç­¾ç»Ÿè®¡
        self.db.rebuild_personal_tag_stats()
        
        logger.info("ä¸ªäººæ ‡ç­¾æ•°æ®æ›´æ–°å®Œæˆ")
    
    def generate_readme(self) -> None:
        """ç”Ÿæˆä¼˜åŒ–çš„ README.md æ–‡ä»¶"""
        logger.info("ç”Ÿæˆ README.md...")
        
        # è·å–ä¸ªäººæ ‡ç­¾ç»Ÿè®¡
        tag_stats = self.db.get_all_personal_tag_stats()
        # åœ¨ç”Ÿæˆå‰ï¼Œå…ˆè§„èŒƒåŒ–ä¸€æ¬¡æ ‡ç­¾ï¼Œç¡®ä¿åªä¿ç•™ 10 ç±»
        self.db.normalize_personal_tags(ORDERED_CATEGORIES, default_tag='others')
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        db_stats = self.db.get_database_stats()
        total_repos = db_stats.get('repositories_count', 0)
        
        # ç”Ÿæˆå¤´éƒ¨å†…å®¹
        content = f"""# âœ¨ My Starred Repositories âœ¨

[![Stars](https://img.shields.io/badge/Total%20Repos-{total_repos}-blue.svg)](https://github.com/vincent623/My-Starred-Repositories)
[![AI Powered](https://img.shields.io/badge/AI%20Powered-ğŸ¤–-brightgreen.svg)](https://github.com/vincent623/My-Starred-Repositories)
[![Auto Updated](https://img.shields.io/badge/Auto%20Updated-âš¡-orange.svg)](https://github.com/vincent623/My-Starred-Repositories/actions)

> ğŸ¤– **AIé©±åŠ¨çš„GitHubæ˜Ÿæ ‡ä»“åº“æ™ºèƒ½ç®¡ç†ç³»ç»Ÿ** - è‡ªåŠ¨åˆ†æã€åˆ†ç±»å’Œç”Ÿæˆæˆ‘æ”¶è—çš„ä¼˜è´¨é¡¹ç›®æ¸…å•

## ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ

"""
        
        # æ·»åŠ ç»Ÿè®¡è¡¨æ ¼
        ordered_tags = [t for t in ORDERED_CATEGORIES if t in tag_stats]
        content += "| åˆ†ç±» | æ•°é‡ | å æ¯” |\n"
        content += "|------|------|------|\n"
        
        for tag in ordered_tags:
            count = tag_stats[tag]
            percentage = (count / total_repos * 100) if total_repos > 0 else 0
            content += f"| {tag} | {count} | {percentage:.1f}% |\n"
        
        content += f"\n**æ€»è®¡**: {total_repos} ä¸ªç²¾é€‰ä»“åº“\n\n"
        
        # ç”Ÿæˆç›®å½•
        content += "## ğŸ“– åˆ†ç±»ç›®å½•\n\n"
        for tag in ordered_tags:
            count = tag_stats[tag]
            anchor = tag.lower().replace(' ', '-').replace('/', '-').replace('&', '')
            content += f"- [{tag}](#{anchor}) ({count}ä¸ª)\n"
        
        content += "\n---\n\n"
        
        # ç”Ÿæˆåˆ†ç±»å†…å®¹ï¼ˆæŠ˜å æ˜¾ç¤ºæ‰€æœ‰é¡¹ç›®ï¼‰
        for tag in ordered_tags:
            anchor = tag.lower().replace(' ', '-').replace('/', '-').replace('&', '')
            count = tag_stats[tag]
            
            # è·å–è¯¥æ ‡ç­¾çš„æ‰€æœ‰ä»“åº“
            repos = self.db.get_repositories_by_personal_tag(tag)
            sorted_repos = sorted(repos, key=lambda x: x['name'])
            
            # ç”ŸæˆæŠ˜å æ ‡é¢˜
            content += f"## {tag}\n\n"
            content += f"<details>\n"
            content += f"<summary><strong>{count} ä¸ªç²¾é€‰é¡¹ç›®</strong> ğŸ‘† ç‚¹å‡»å±•å¼€</summary>\n\n"
            
            # å¦‚æœé¡¹ç›®è¾ƒå¤šï¼Œæ·»åŠ é¡¶éƒ¨å¿«é€Ÿé¢„è§ˆï¼ˆå‰3ä¸ªï¼‰
            if count > 3:
                content += "### ğŸŒŸ ç²¾é€‰æ¨è\n\n"
                for repo in sorted_repos[:3]:
                    language = repo.get('language', 'Unknown')
                    summary = repo.get('summary', 'No summary')
                    url = repo['html_url']
                    content += f"- **[{repo['name']}]({url})** `{language}` - {summary}\n"
                content += f"\n### ğŸ“‹ å®Œæ•´åˆ—è¡¨ ({count} ä¸ªé¡¹ç›®)\n\n"
            
            # ç”Ÿæˆå®Œæ•´é¡¹ç›®åˆ—è¡¨
            for repo in sorted_repos:
                language = repo.get('language', 'Unknown')
                summary = repo.get('summary', 'No summary')
                url = repo['html_url']
                
                # ç®€åŒ–æ˜¾ç¤ºæ ¼å¼
                content += f"- **[{repo['name']}]({url})** `{language}` - {summary}\n"
            
            content += "\n</details>\n\n"
        
        # æ·»åŠ é¡¹ç›®è¯´æ˜å’Œé¡µè„š
        content += f"""---

## ğŸš€ å…³äºæœ¬é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ª**AIé©±åŠ¨çš„GitHubæ˜Ÿæ ‡ä»“åº“ç®¡ç†ç³»ç»Ÿ**ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹æ€§ï¼š

- ğŸ¤– **æ™ºèƒ½åˆ†æ**: ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨åˆ†ææ¯ä¸ªä»“åº“çš„ä»·å€¼å’Œç”¨é€”
- ğŸ·ï¸ **æ™ºèƒ½åˆ†ç±»**: è‡ªåŠ¨å½’ç±»åˆ°10å¤§æŠ€æœ¯é¢†åŸŸ
- ğŸ“Š **æ•°æ®æ´å¯Ÿ**: æä¾›è¯¦ç»†çš„ç»Ÿè®¡åˆ†æå’Œè¶‹åŠ¿æ´å¯Ÿ
- âš¡ **è‡ªåŠ¨æ›´æ–°**: é€šè¿‡GitHub Actionsæ¯å‘¨è‡ªåŠ¨æ›´æ–°
- ğŸ”’ **éšç§å®‰å…¨**: æœ¬åœ°æ•°æ®åº“å­˜å‚¨ï¼Œä»£ç å®Œå…¨å¼€æº

### ğŸ“‹ æŠ€æœ¯æ ˆ

- **åç«¯**: Python 3.11+ + SQLite
- **AIæ¨¡å‹**: æ”¯æŒOpenRouterã€OpenAIã€Silicon Flowç­‰å¤šç§LLM
- **è‡ªåŠ¨åŒ–**: GitHub Actions
- **æ•°æ®å¤„ç†**: æ™ºèƒ½æ ‡ç­¾åˆå¹¶ä¸å»é‡

### ğŸ¯ å¿«é€Ÿå¼€å§‹

1. **Forkæœ¬ä»“åº“**: [My-Starred-Repositories](https://github.com/vincent623/My-Starred-Repositories)
2. **é…ç½®Secrets**: å‚è€ƒ [GITHUB_ACTIONS_SETUP.md](./GITHUB_ACTIONS_SETUP.md)
3. **æ‰‹åŠ¨è¿è¡Œ**: åœ¨Actionsé¡µé¢è§¦å‘é¦–æ¬¡è¿è¡Œ
4. **äº«å—è‡ªåŠ¨åŒ–**: æ¯å‘¨ä¸€è‡ªåŠ¨æ›´æ–°åˆ†æ

### ğŸ“š æ–‡æ¡£

- ğŸ“– [è¯¦ç»†è®¾ç½®æŒ‡å—](./SETUP.md)
- âš™ï¸ [GitHub Actionsé…ç½®](./GITHUB_ACTIONS_SETUP.md)
- ğŸ“‹ [äº§å“éœ€æ±‚æ–‡æ¡£](./prd.md)

---

*ğŸ“… æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | ğŸ¤– è‡ªåŠ¨ç”Ÿæˆ by [My Starred Repositories V3](https://github.com/vincent623/My-Starred-Repositories)*
"""
        
        # ä¿å­˜æ–‡ä»¶
        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info("README.md ç”Ÿæˆå®Œæˆ")
    
    def generate_weekly_report(self, new_repos: List[Dict]) -> None:
        """ç”Ÿæˆæ¯å‘¨æŠ¥å‘Š"""
        if not new_repos:
            logger.info("æœ¬å‘¨æ²¡æœ‰æ–°å¢ Star ä»“åº“ï¼Œè·³è¿‡å‘¨æŠ¥ç”Ÿæˆ")
            return
        
        logger.info("ç”Ÿæˆæ¯å‘¨æŠ¥å‘Š...")
        
        # å‡†å¤‡æ•°æ®
        weekly_data = []
        for repo in new_repos:
            weekly_data.append(f"""
ä»“åº“ï¼š{repo['name']}
è¯­è¨€ï¼š{repo['language']}
GitHubä¸»é¢˜ï¼š{', '.join(repo.get('github_topics', []))}
æ‘˜è¦ï¼š{repo['summary']}
ä¸ªäººæ ‡ç­¾ï¼š{', '.join(repo['tags'])}
ä»·å€¼ï¼š{repo['value']}
""")
        
        weekly_text = "\n".join(weekly_data)
        
        # è°ƒç”¨ LLM ç”ŸæˆæŠ¥å‘Š
        prompt = REPORT_SUMMARY_PROMPT.format(weekly_data=weekly_text)
        
        try:
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=LLM_TEMPERATURE,
                max_tokens=1000
            )
            
            report_content = response.choices[0].message.content
            
            # æ·»åŠ æ ‡é¢˜å’Œæ—¶é—´
            final_report = f"""# My Starred Repos Weekly Insight Report - {datetime.now().strftime('%Y-%m-%d')}

{report_content}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*è‡ªåŠ¨ç”Ÿæˆ by My Starred Repositories V3*
"""
            
            # ä¿å­˜æŠ¥å‘Šï¼ˆè¦†ç›–æœ€æ–°ï¼‰
            with open(WEEKLY_REPORT_FILE, 'w', encoding='utf-8') as f:
                f.write(final_report)

            # å½’æ¡£ä¸€ä»½å‘¨æŠ¥ï¼ˆå•ç‹¬ä¿å­˜ï¼‰
            try:
                os.makedirs(WEEKLY_REPORT_DIR, exist_ok=True)
                today = datetime.now()
                # é‡‡ç”¨ ISO å‘¨ç¼–å·å‘½å
                iso_year, iso_week, _ = today.isocalendar()
                archive_name = WEEKLY_REPORT_FILENAME_TEMPLATE_ISOWEEK.format(
                    year=iso_year, week=iso_week
                )
                archive_path = os.path.join(WEEKLY_REPORT_DIR, archive_name)
                with open(archive_path, 'w', encoding='utf-8') as f:
                    f.write(final_report)
            except Exception as arch_e:
                logger.warning(f"å‘¨æŠ¥å½’æ¡£å¤±è´¥: {arch_e}")
            
            logger.info("æ¯å‘¨æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¯å‘¨æŠ¥å‘Šå¤±è´¥: {e}")
    
    def run(self, mode: str = "auto", force_reanalyze: bool = False, sample: Optional[int] = None, rebuild_only: bool = False) -> None:
        """è¿è¡Œä¸»ç¨‹åº"""
        try:
            logger.info("å¼€å§‹è¿è¡Œ My Starred Repositories V3...")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            # 1. è·å– Star ä»“åº“å¹¶ç›´æ¥å†™å…¥æ•°æ®åº“ï¼ˆæ¯æ—¥/æ¯å‘¨éƒ½åº”æ‰§è¡ŒåŒæ­¥ï¼‰
            self.get_starred_repositories()
            
            # 2. å¤„ç†ä»“åº“åˆ†æï¼ˆæ”¯æŒå¼ºåˆ¶/æŠ½æ ·ï¼‰
            new_repos = []
            if not rebuild_only:
                new_repos = self.process_repositories(force_reanalyze=force_reanalyze, limit=sample)
            
            # 3. æ›´æ–°æ ‡ç­¾æ•°æ®
            self.update_tags_data()
            
            # 4. ç”Ÿæˆ README.md
            self.generate_readme()
            
            # 5. ç”Ÿæˆæ¯å‘¨æŠ¥å‘Šï¼ˆæŒ‰æ¨¡å¼/å‘¨æœŸæ§åˆ¶ï¼‰
            should_generate_weekly = False
            if mode == "weekly":
                should_generate_weekly = True
            elif mode == "auto":
                # æ¯å‘¨ä¸€ç”Ÿæˆ
                try:
                    should_generate_weekly = datetime.now().weekday() == 0
                except Exception:
                    should_generate_weekly = False
            # daily æ¨¡å¼ä¸ç”Ÿæˆ

            if should_generate_weekly:
                self.generate_weekly_report(new_repos)
            
            # è®°å½•å¤„ç†å†å²
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            self.db.log_processing_history(
                action="full_run_v3",
                details={
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration": duration,
                    "new_repos": len(new_repos)
                }
            )
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = self.db.get_database_stats()
            logger.info("æ•°æ®åº“ V3 ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                logger.info(f"  {key}: {value}")
            
            logger.info("æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
            # è®°å½•é”™è¯¯å†å²
            try:
                self.db.log_processing_history(
                    action="full_run_v3",
                    details={"error": str(e)},
                    status="error"
                )
            except:
                pass
            raise

@click.command()
@click.option('--debug', is_flag=True, help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
@click.option('--stats', is_flag=True, help='æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯')
@click.option('--init-dict', is_flag=True, help='åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸')
@click.option('--show-dict', is_flag=True, help='æ˜¾ç¤ºä¸ªäººæ ‡ç­¾è¯å…¸')
@click.option('--mode', type=click.Choice(['daily', 'weekly', 'auto']), default='auto', show_default=True, help='è¿è¡Œæ¨¡å¼ï¼šdaily=æ¯æ—¥æ›´æ–°READMEï¼›weekly=ä»…ç”Ÿæˆæœ¬å‘¨æ´å¯Ÿï¼›auto=æ¯æ—¥æ›´æ–°ä¸”æ¯å‘¨ä¸€ç”Ÿæˆæ´å¯Ÿ')
@click.option('--reset-tags', is_flag=True, help='å°†ä¸ªäººæ ‡ç­¾è¯å…¸é‡ç½®ä¸ºé…ç½®çš„ 10 å¤§ä¸»ç±»')
@click.option('--force-reanalyze', is_flag=True, help='å¼ºåˆ¶å…¨é‡é‡åˆ†æï¼ˆå¿½ç•¥ analyzed_at é˜ˆå€¼ï¼‰')
@click.option('--sample', type=int, default=None, help='ä»…åˆ†æå‰ N ä¸ªä»“åº“ç”¨äºå¿«é€ŸéªŒè¯')
@click.option('--rebuild-only', is_flag=True, help='ä¸åˆ†æï¼Œä»…é‡å»ºç»Ÿè®¡å¹¶ç”Ÿæˆ README')
def main(debug, stats, init_dict, show_dict, mode, reset_tags, force_reanalyze, sample, rebuild_only):
    """ä¸»å‡½æ•°"""
    if debug:
        logger.add("debug.log", level="DEBUG")
    
    try:
        manager = StarredReposManagerV3()
        
        if stats:
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = manager.db.get_database_stats()
            print("æ•°æ®åº“ V3 ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                print(f"  {key}: {value}")
            return
        
        if init_dict:
            # åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸
            logger.info("åˆå§‹åŒ–ä¸ªäººæ ‡ç­¾è¯å…¸...")
            manager._initialize_personal_tag_dictionary()
            logger.info("ä¸ªäººæ ‡ç­¾è¯å…¸åˆå§‹åŒ–å®Œæˆ")
            return
        
        if show_dict:
            # æ˜¾ç¤ºä¸ªäººæ ‡ç­¾è¯å…¸
            dictionary = manager.db.get_personal_tag_dictionary()
            print("ä¸ªäººæ ‡ç­¾è¯å…¸:")
            for item in dictionary:
                print(f"  {item['tag']} - {item['category']}: {item['description']}")
            return
        
        if reset_tags:
            # é‡ç½®ä¸ªäººæ ‡ç­¾è¯å…¸ä¸º 10 å¤§ä¸»ç±»
            manager.db.reset_personal_tag_dictionary(ORDERED_CATEGORIES)
            logger.info("å·²å°†ä¸ªäººæ ‡ç­¾è¯å…¸é‡ç½®ä¸º 10 å¤§ä¸»ç±»")
            return
        
        # æ­£å¸¸è¿è¡Œ
        manager.run(mode=mode, force_reanalyze=force_reanalyze, sample=sample, rebuild_only=rebuild_only)
        
    except Exception as e:
        logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        exit(1)

if __name__ == "__main__":
    main()
